"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[9095],{6243:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>d});var i=s(4848),r=s(8453);const l={sidebar_position:3},c="Text-To-Speech (TTS)",t={id:"references/tts",title:"Text-To-Speech (TTS)",description:"Overview",source:"@site/content/references/tts.md",sourceDirName:"references",slug:"/references/tts",permalink:"/xrx-core/docs/references/tts",draft:!1,unlisted:!1,editUrl:"https://github.com/8090-inc/xrx-core/blob/main/docs/content/references/tts.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Speech-To-Text (STT)",permalink:"/xrx-core/docs/references/stt"},next:{title:"Reasoning Agent",permalink:"/xrx-core/docs/references/agent"}},o={},d=[{value:"Overview",id:"overview",level:2},{value:"Endpoint",id:"endpoint",level:3},{value:"Authentication",id:"authentication",level:3},{value:"Connection",id:"connection",level:3},{value:"Messages",id:"messages",level:3},{value:"JSON Messages",id:"json-messages",level:4},{value:"Events",id:"events",level:3},{value:"<code>message</code>",id:"message",level:4},{value:"<code>close</code>",id:"close",level:4},{value:"Server Responses",id:"server-responses",level:3},{value:"Binary Responses",id:"binary-responses",level:4},{value:"JSON Responses",id:"json-responses",level:4},{value:"Error Handling",id:"error-handling",level:3},{value:"Environment Variables",id:"environment-variables",level:3},{value:"Supported TTS Providers",id:"supported-tts-providers",level:3},{value:"Technical Details",id:"technical-details",level:2},{value:"TTS Interface",id:"tts-interface",level:3},{value:"Example Usage",id:"example-usage",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"text-to-speech-tts",children:"Text-To-Speech (TTS)"}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"The Text-to-Speech (TTS) module is a FastAPI service that provides real-time synthesis of text to speech using multiple TTS providers. This module establishes a WebSocket connection to receive text input and returns synthesized speech in binary format."}),"\n",(0,i.jsx)(n.h3,{id:"endpoint",children:"Endpoint"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"URL:"})," ",(0,i.jsx)(n.code,{children:"/api/v1/ws"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Method:"})," ",(0,i.jsx)(n.code,{children:"GET"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Protocol:"})," WebSocket"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"authentication",children:"Authentication"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Header:"})," None required for the WebSocket connection itself."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environment Variables:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"TTS_PROVIDER"}),': Specifies the TTS provider to use (default: "elevenlabs")']}),"\n",(0,i.jsxs)(n.li,{children:["Provider-specific API keys and settings (see ",(0,i.jsx)(n.a,{href:"#environment-variables",children:"Environment Variables"})," section)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"connection",children:"Connection"}),"\n",(0,i.jsx)(n.p,{children:"Upon connecting to the WebSocket endpoint, the server initializes the specified TTS provider and prepares to handle incoming messages."}),"\n",(0,i.jsx)(n.h3,{id:"messages",children:"Messages"}),"\n",(0,i.jsx)(n.p,{children:"The server handles JSON messages to initiate or cancel the text-to-speech synthesis process."}),"\n",(0,i.jsx)(n.h4,{id:"json-messages",children:"JSON Messages"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Format:"})," JSON"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"action"}),": ",(0,i.jsx)(n.code,{children:'"synthesize"'})," or ",(0,i.jsx)(n.code,{children:'"cancel"'})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"text"}),": The text content to be synthesized (required if ",(0,i.jsx)(n.code,{children:"action"})," is ",(0,i.jsx)(n.code,{children:'"synthesize"'}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "action": "synthesize",\n  "text": "Hello, how can I assist you today?"\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"events",children:"Events"}),"\n",(0,i.jsx)(n.h4,{id:"message",children:(0,i.jsx)(n.code,{children:"message"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Triggered when a message is received from the client."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"message"}),": The message data (JSON)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Handling Synthesize Messages:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["If ",(0,i.jsx)(n.code,{children:"action"})," is ",(0,i.jsx)(n.code,{children:'"synthesize"'}),", the server will begin the synthesis process and stream the resulting audio data back to the client."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Handling Cancel Messages:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["If ",(0,i.jsx)(n.code,{children:"action"})," is ",(0,i.jsx)(n.code,{children:'"cancel"'}),", the server will cancel any ongoing synthesis tasks."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"close",children:(0,i.jsx)(n.code,{children:"close"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," Triggered when the client closes the connection."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"server-responses",children:"Server Responses"}),"\n",(0,i.jsx)(n.h4,{id:"binary-responses",children:"Binary Responses"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Format:"})," Binary data (audio data)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Description:"})," The synthesized speech audio data is sent in chunks as it is received from the TTS provider."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"json-responses",children:"JSON Responses"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Format:"})," JSON"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"action"}),": Indicates completion with ",(0,i.jsx)(n.code,{children:'"done"'})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "action": "done"\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"If the TTS provider connection fails or an error occurs during synthesis, the server logs the error and closes the WebSocket connection."}),"\n",(0,i.jsx)(n.li,{children:"The server caches synthesized audio to avoid redundant processing for identical text inputs."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"TTS_PROVIDER"}),': Specifies the TTS provider to use (default: "elevenlabs")']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"TTS_SAMPLE_RATE"}),": Specifies the sample rate for the TTS output (default: 24000Hz)"]}),"\n",(0,i.jsxs)(n.li,{children:["ElevenLabs:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ELEVENLABS_API_KEY"}),": API key for ElevenLabs authentication"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ELEVENLABS_VOICE_ID"}),": Voice ID for the ElevenLabs TTS service"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ELEVENLABS_MODEL_ID"}),': Model ID for ElevenLabs (default: "eleven_turbo_v2.5")']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ELEVENLABS_VOICE_STABILITY"}),": Voice stability setting (default: 0.9)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ELEVENLABS_VOICE_SIMILARITY"}),": Voice similarity setting (default: 0.9)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["OpenAI:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"OPENAI_API_KEY"}),": API key for OpenAI authentication"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"OPENAI_TTS_MODEL"}),': OpenAI TTS model to use (default: "tts-1")']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"OPENAI_TTS_VOICE"}),': OpenAI TTS voice to use (default: "alloy")']}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Deepgram:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"DG_API_KEY"}),": API key for Deepgram authentication"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"DG_TTS_MODEL_VOICE"}),': Deepgram TTS model and voice (default: "aura-asteria-en")']}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Cartesia:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CARTESIA_API_KEY"}),": API key for Cartesia authentication"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CARTESIA_VOICE_ID"}),": Voice ID for the Cartesia TTS service"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CARTESIA_MODEL_ID"}),': Model ID for Cartesia (default: "sonic-english")']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CARTESIA_VERSION"}),': API version for Cartesia (default: "2024-06-10")']}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CACHE_DIR"}),': Directory for caching audio data (default: "cache")']}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"supported-tts-providers",children:"Supported TTS Providers"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"ElevenLabs"}),"\n",(0,i.jsx)(n.li,{children:"OpenAI"}),"\n",(0,i.jsx)(n.li,{children:"Deepgram"}),"\n",(0,i.jsx)(n.li,{children:"Cartesia"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"technical-details",children:"Technical Details"}),"\n",(0,i.jsx)(n.h3,{id:"tts-interface",children:"TTS Interface"}),"\n",(0,i.jsxs)(n.p,{children:["The TTS service uses an abstract base class ",(0,i.jsx)(n.code,{children:"TTSInterface"})," that defines the common interface for all TTS providers. Each provider implements this interface with the following abstract methods:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class TTSInterface(ABC):\n    @abstractmethod\n    async def initialize(self):\n        """Initialize the TTS service."""\n        pass\n\n    @abstractmethod\n    async def synthesize(self, text: str):\n        """Synthesize text to audio and yield audio chunks."""\n        pass\n\n    @abstractmethod\n    async def close(self):\n        """Close the connection to the service."""\n        pass\n\n    @property\n    @abstractmethod\n    def is_open(self) -> bool:\n        """Check if the connection is open."""\n        pass\n'})}),"\n",(0,i.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Connecting to the WebSocket:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const socket = new WebSocket('ws://localhost:8002/api/v1/ws');\n\nsocket.onopen = () => {\n  console.log('Connection opened');\n};\n\nsocket.onmessage = (event) => {\n  if (typeof event.data === 'string') {\n    const message = JSON.parse(event.data);\n    if (message.action === 'done') {\n      console.log('Synthesis completed');\n    }\n  } else {\n    console.log('Received binary audio data');\n    // Handle audio data (e.g., play it or save it)\n  }\n};\n\nsocket.onclose = (event) => {\n  console.log('Connection closed');\n};\n\nsocket.onerror = (error) => {\n  console.error('WebSocket error:', error);\n};\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Sending a Synthesize Message:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const message = {\n  action: 'synthesize',\n  text: 'Hello, how can I assist you today?'\n};\nsocket.send(JSON.stringify(message));\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Sending a Cancel Message:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const message = {\n  action: 'cancel'\n};\nsocket.send(JSON.stringify(message));\n"})}),"\n",(0,i.jsx)(n.p,{children:"This documentation provides an overview of the Text-to-Speech WebSocket API, including connection details, message formats, events, supported providers, and example usage. The API supports multiple TTS providers and includes configuration options through environment variables."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>c,x:()=>t});var i=s(6540);const r={},l=i.createContext(r);function c(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);